---
title: "Google SRE 运维解密笔记"
date: 2020-09-23T11:00:43+08:00
tags:
  - Google
  - SRE
  - notes
categories:
  -
---

本书对于 SRE 的定义

> 我们认为如果软件工程师主要专注于设计和构建软件系统，那么应该有另外一种职业专注于整个软件系统的生命周期管理。从其设计一直到部署，历经不断改进，最后顺利退役。这样一种职业必须具备非常广泛的技能，但是和其他职业的专注点都不同。Google 将这个职业称为站点可靠性工程师(SRE: Site Reliability Engineering)。

"无论对一个软件系统运行原理掌握得多么彻底，也不能阻止人犯意外错误。"

**只有靠着对细节的不懈关注，做好充足的灾难预案和准备工作，时刻警惕着，不放过一切机会去避免灾难发生。这就是 SRE 最重要的理念！**

## 第一章：介绍

> 不能将碰运气当成战略。 - SRE 俗语

SRE 团队要承担以下几类职责

- 可用性改进
- 延迟优化
- 性能优化
- 效率优化
- 变更管理
- 监控
- 紧急事务处理
- 容量规划与管理

### 在保障服务 SLO 的前提下最大化迭代速度

在企业中，最主要的矛盾就是迭代创新的速度与产品稳定程度之间的矛盾。
在 SRE 模型中，我们选择正面面对这种矛盾，使用的工具是`错误预算`。

> "错误预算"起源于这样一个理念： 任何产品都不是，也不应该做到 100%可靠(显然这并不适用于心脏起博器和防抱死系统等)。因为对最终用户来说，99.999%和 100%的可用性是没有实质区别的。

多少才是？

- 基于用户的使用习惯，服务可靠性要达到什么程度用户才会满意？
- 如果这项服务的可靠程度不够，用户是否有其他的替代选择？
- 服务的可靠程度是否会影响用户对这项服务的使用模式？

如果一个服务的可靠性目标是 99.99%，那么错误预算就是 0.01%。这意味着产品研发部门和 SRE 部门可以在这个范围内将预算用于新功能上线或产品创新等任何事情。

### 监控系统

监控系统是 SRE 团队监控服务质量和可用性的一个主要手段。

> 一个需要人工阅读邮件和分析警报来决定目前是否需要采取某种行动的系统本质上就是错误的。监控系统不应该依赖人来分析警报信息，而是应该由系统自动分析，仅当需要用户执行某种操作时，才需要通知用户。

一个监控系统应该只有三类输出

- 紧急警报 - alert
  > 意味着收到警报的用户需要立即执行某种操作，目标是解决某种已经发生的问题，或者是避免即将发生的问题。
- 工单 - ticket
  > 意味着接受工单的用户应该执行某种操作，但是并非立即执行。系统并不能自动解决目前的情况，但是如果一个用户在几天内执行这项操作，系统不会受到任何影响。
- 日志 - logging
  > 平时没有人需要关注日志信息，但是日志信息依然被收集起来以备调试和事后分析时使用。正确的做法是平时没人会去主动阅读日志，除非有特殊需要。

### 变更管理

大概 70%的生产事故由某种部署的变更而触发。变更管理的最佳实践是使用自动化来完成以下几个项目

- 采用渐进式发布机制
- 迅速而准确地检测到问题的发生
- 当出现问题时，安全迅速地回退改动

### 需求预测和容量规划

自然增长 - 随着用户使用量上升，资源用量也上升。
非自然增长 - 新功能的发布、商业推广以及其他商业因素在内。

容量规划有几个步骤是必需的

- 必须有一个准确的自然增长需求预测模型，需求预测的时间应该超过资源获取的时间
- 规划中必须有准确的非自然增长的需求来源的统计
- 必须有周期性压力测试，以便准确地将系统原始资源信息与业务容量对应起来

## 第二章：Google 生产环境： SRE 视角

为了区分物理服务器和软件服务器的概念，本书采用以下两种说法

- 物理服务器 - machine
  > 代表具体的硬件(有时候也代表一个 VM 虚拟机)
- 软件服务器 - server
  > 代表一个对外提供服务的软件系统

一个典型的 Google 数据中心的拓扑结构

- 约 10 台物理服务器组成一个`机柜 - Rack`
- 数台机柜组成一个机柜`排 - Row`
- 一排或多排机柜组成了一个`集群 - Cluster`
- 一般来说，一个`数据中心 - Datacenter`包含多个集群
- 多个相邻的数据中心组成了一个`园区 - Campus`

### 存储

- Lustre
- HDFS

### 网络

带宽控制器(Bandwidth Enforcer， BwE)负责管理所有可用带宽。优化带宽的使用的目的不仅仅是降低成本。利用中心化的路由计算，可以解决以前在分布式路由模式下难以解决的流量迁移问题。

### 研发环境

除了一些开源项目之外(Android 和 Chrome 等)，其他 Google 软件工程师全部使用同一个共享软件仓库开发。这同时也对日常工作流带来一些挑战

- 如果一个工程师遇到了他工作的项目之外的一个基础组件问题，他可以直接修改这个问题，向管理者提交一份改动申请(changelist, CL)，等待代码评审，最后直接提交。
- 任何对自己项目代码的改动也需要代码评审。

### 任务和数据的组织方式

假设压力测试的结果现实，我们的软件服务器可以每秒处理大概 100 个请求(100 QPS)。通过对用户进行的调查显示，我们预计峰值流量会达到 3470 QPS，为了处理这些流量，至少需要 35 个任务实例。但是，由于以下几点考量，我们最终决定至少采用 37 个实例，也就是`N+2`模式

- 在更新过程中，有一个任务实例将会短暂不可用，只有 36 个实例可提供服务。
- 如果另外一个物理服务器同时也出现问题，那么另外一个任务实例也受到影响，只剩 35 个实例可以对外服务，刚好可以满足峰值要求。

## 第三章：拥抱风险

过分追求稳定性限制了新功能的开发速度和将产品交付给用户的速度，并且很大程度地增加了成本，这反过来又减少了一个团队可以提供的新功能数量。
此外，用户通常不会注意到一项服务在高可靠性和极端可靠性直接的差异，因为用户体验主要是受较不可靠的组件主导，例如手机移动网络或他们正在使用的设备。用户在一个有着 99%可靠性的智能手机上是不能分辨出 99.99%和 99.999%的服务可靠性的区别的！

SRE 旨在寻求快速创新和高效的服务运营业务之间的风险的平衡，而不是简单地将服务在线时间最大化。这样一来，我们可以优化用户的整体幸福感，平衡系统的功能、服务和性能

### 管理风险

可靠性进一步提升的成本并不是线性增加的 - 可靠性的下一个改进可能比之前的改进成本增加 100 倍。
高昂的成本主要存在与

- 冗余物理服务器/计算资源成本
  > 通过投入冗余设备，我们可以进行常规的系统离线或其他预料之外的维护性操作。又或者可以利用一些空间来存储奇偶校验码块，以此来提供一定程度的数据持久性保证。
- 机会成本
  > 这类成本由某一个组织承担。当该组织分配工程资源来构建减少风险的系统或功能，而非那些用户直接可用的功能时需要承担这些成本。这些工程师不能再从事为终端用户设计新功能和新产品的工作。

我们会努力提高一项服务的可靠性，但不会超过该服务需要的可靠性。当设定了一个可用性目标为 99.99%时，我们即使要超过这个目标，也不会超过太多，否则会浪费为系统增加新功能、清理技术债务或降低运营成本的机会。

### 度量服务的风险

为了使问题在我们运行的各种类型的系统中易于处理，并且保持一致，我们选择主要关注`计划外停机`这个指标。

计划外停机时间是由服务预期的可用性水平所体现，通常我们愿意用提供的"9"系列的数字来体现，比如可用性为`99.9%/99.99%或99.999%`。每个额外的"9"都对应一个向`100%`可用性的数量级上提高。对于系统服务而言，这个指标通常是基于系统正常运行时间比例的计算得出的。

#### 公式 3-1： 基于时间的可用性

可用性=系统正常运行时间/(系统正常运行时间+停机时间)

#### 公式 3-2： 合计可用性

可用性=成功请求数/总的请求数

> 例如，一个每天可用性目标为 99.99%的系统，一天要接受 2.5M 个请求。它每天出现少于 250 个错误即可达到预计的可用性目标。

### 服务的风险容忍度

#### 辨别消费者服务的风险容忍度

消费者服务通常会有一个对应的产品团队，是该服务的商业所有者。比如说，Search、Google Maps 和 Google Docs，它们每一个都有自己的产品经理。这产品经理负责了解用户和业务，在市场上塑造产品的定位。存在产品团队时，我们能够更好地通过这个团队来讨论服务的可靠性要求。在没有专门的产品团队情况下，建立系统的工程师们经常在知情或不知情的情况下扮演了这个角色。
评价服务的风险容忍度时，有许多需要考虑的因素。

- 需要的可用性水平是什么？
- 不同类型的失败对服务有不同的影响吗？
- 我们如何使用服务成本来帮助风险曲线上定位这个服务？
- 有哪些其他重要的服务指标需要考虑？

##### 可用性目标

对于某个 Google 服务而言，服务的可用性目标通常取决于它提供的功能，以及这项服务在市场上是如何定位的。下面列出了要考虑的一些问题

- 用户期望的服务水平是什么？
- 这项服务是否直接关系收入(我们的收入或我们的客户的收入)？
- 这是一个有偿服务，还是免费服务？
- 如果市场上有竞争对手，那些竞争对手提供的服务水平如何？
- 这项服务是针对消费者还是企业的？

例如`Google Apps for Work`，这个服务的主要用户是企业类用户，包括大型企业和中小型企业。服务的中断不仅会影响 Google 本身，也会影响到这些企业。对于这类服务，我们可能会设置季度性的外部可用性目标为 99.9%。同时，我们会设置一个更高的内部可用性目标，以及签署一份如果我们未能达到外部目标的处罚性协议。
Youtube 则需要截然不同的考虑。尽管当时 Youtube 已经有了一个很出色的产品，但它仍然在不断变化和快速发展着。因此，我们为 Youtube 设定了相比我们企业的产品更低的可用性目标，因为快速发展更加重要。

##### 故障的类型

假设有一个联系人管理应用程序，一种情况是导致用户头像显示失败的间歇性故障，另一种情况是将 A 用户的私人联系人列表显示给 B 用户的故障。第一种情况显然是一个糟糕的用户体验，SRE 会努力去快速地解决这个问题。然而，在第二种情况下，暴露私人数据的风险可能会破坏基本的用户信任。因此，在第二种情况下，在进行调试和事后的数据清理时，完全停止该服务更加恰当。
有时候，我们可以接受计划内的常规服务中断。Ads 前端曾经就是这样的一种服务。因为这项工作大部分发生在正常工作时间内，我们认为维修窗口中发生的偶然的、正常的、计划之中的故障是可以接受的，并且我们把这些故障看作计划内停机(不影响 SLO？)，而不是计划外停机时间。

##### 成本

在为每一项服务确定可用性目标时，可以考虑如下问题

- 构建和运维可用性再多一个"9"的系统，收益会增加多少？
- 额外的收入是否能抵消为了达到这一可靠性水平所付出的成本？

> 可靠性目标： 99.9% -> 99.99%
>
> 增加的可用性： 0.09%
>
> 服务收入： 100 万美元
>
> 改进可用性后的价值： 100 万美元 x 0.0009 = 900 美元
>
> 在这种情况下，如果可用性提高一个"9"的成本不到 900 美元，那就是合理的投资。如果成本超过 900 美元，那么成本将超过预计增加的收入。

### 错误预算的构建过程

- 产品管理层定义一个 SLO，确定一项服务在每个季度的正常运行时间。
- 实际在线时间是通过一个中立的第三方来测算的： 我们的监控系统。
- 这两个数字的差值就是这个季度中剩余的不可靠性预算。
- 只要测算出的正常在线时间高于 SLO，也就是说，只要仍然有剩余的错误预算，就可以发布新版本。

### 本章关键点

- 管理服务的可靠性主要在与管理风险，而且管理风险的成本可能很高。
- 100%可能永远都不是一个正确的可靠性目标： 不仅是不可能实现的，而且它通常比一项服务的用户期望的可靠性大得多。我们要将服务风险和愿意承担的业务风险相匹配。
- 错误预算在 SRE 和产品研发团队之间调整激励，同时强调共同责任。错误预算使得讨论发布速率更容易，同时可有效地减少任何关于事故的讨论。这样，多个团队可以毫无怨言地对生产环境风险度达成一致。

## 服务质量目标

这个过程中，我们需要利用一些主观判断结合过去的经验对服务的理解来定义一些`服务质量指标(SLI)`、`服务质量目标(SLO)`，以及`服务质量协议(SLA)`。这三项分别是指该服务最重要的一些基础指标、这些指标的预期值，以及当指标不符合预期时的应对计划。

### 服务质量术语

#### 指标(Indicator)

SLI 是指服务质量指标 - 该服务的某项服务质量的一个具体量化指标。
大部分服务都将`请求延迟`(处理请求所消耗的时间)作为一个关键 SLI。其他常见的 SLI 包括`错误率`(请求处理失败的百分比)、`系统吞吐量`(每秒请求数量)等。这些度量通常是汇总过的： 在某一个度量时间范围内将原始数据收集起来，计算速率、平均值、百分比等汇总数据。
`可用性`(availability)是另外一个重要的 SLI，代表服务可用时间的百分比。对于数据存储系统来说，`持久性`(durability) - 数据能够完整保存的时间也是一个重要指标。

#### 目标(Objective)

SLO 是服务质量目标 - 服务的某个 SLI 的目标值，或者目标范围。
SLO 的定义是 `SLI ≤ 目标值`，或者`范围下限 ≤ SLI ≤ 范围上限`。

#### 协议(Agreement)

SLA 是服务质量协议 - 指服务与用户之间的一个明确的，或者不明确的协议，描述了在达到或者没有达到 SLO 之后的后果。
区别 SLO 和 SLA 的一个简单的方法就是问"如果 SLO 没有达到目标，有什么后果？" 如果没有定义明确的后果，那么我们就肯定是在讨论一个 SLO，而不是 SLA。

### 指标在实践中的应用

#### 运维人员和最终用户各关心什么

我们不应该将监控系统中的所有指标都定义 SLI；只有理解用户对系统的真实需求才能真正决定哪些指标是否有用。一般来说四五个具有代表性的指标对系统健康程度的评估和关注就足够了。
常见的服务，根据它们的相关 SLI 通常会归类为以下几个大类。

- `用户可见的服务系统`，例如莎士比亚搜索服务的前端服务器通常关系可用性、延迟，以及吞吐量。换句话说： 是否能正常处理请求？每个请求花费的时间是多少？多少请求可以被处理？
- `存储系统`通常强调： 延迟、可用性和数据持久性。换句话说： 读写数据需要多少时间？我们是否可以随时访问数据？数据是否一段时间内还能被读取？
- `大数据系统`，例如数据处理流水线系统，一般来说关系吞吐量和端到端延迟。换句话说： 处理了多少数据？数据从输入到产出需要多少时间？(某些流水线任务还会关注某个单独处理阶段的延迟)
- 所有的系统都应该关注： `正确性`。是否返回了正确的回复，是否读取了正确的数据，或者进行了正确的数据分析操作。正确性是系统健康程度的一个重要指标，但是它更关注系统内部的数据，而不是系统本身，所以这通常不是 SRE 直接负责的。

### 目标在实践中的应用

我们应该从思考(或者调研)用户最关心的方面入手，而非从现在能度量什么入手。用户真正关心的部分经常是度量起来很困难，甚至是不可能的，所以我们需要以某种形式近似。如果我们只是从可以简单度量的数值入手，最终的 SLO 的作用就会很有限。
因此，与其选择指标，再想出对应的目标，不如从想要的目标反向推导出具体的指标。

#### 目标的选择

- 不要仅以目前的状态为基础选择目标
  > 了解系统的各项指标和限制非常重要，但是仅仅按照当前系统的标准制定目标，而不从全局出发，可能会导致团队被迫长期运维一个过时的系统，没有时间去推动架构重构等任务
- 保持简单
  > SLI 中过于复杂的汇总模式可能会掩盖某种系统性能的变化，同时也更难以理解。
- 避免绝对值
  > 虽然要求系统可以在没有任何延迟增长的情况下无限扩张，或者"永远"可用是很诱人的，但是这样的要求是不切实际的。就算有一个系统能够做到这一点，它也需要花很长时间来设计和构建，同时运维也很复杂，最关键的是，这可能比用户可以接受的(甚至是很开心接受的)标准要高太多。
- SLO 越少越好
  > 应该仅仅选择足够的 SLO 来覆盖系统属性，一定要确保每一个 SLO 都是必不可少的： 如果我们无法针对某个 SLO 达标问题说服开发团队，那么可能这个 SLO 就是不必要的(**如果 SRE 团队无法说服研发团队接受任何一个 SLO，那么这个产品可能压根不需要 SRE 团队的支持**)。然而，不是所有的产品属性都能用 SLO 表达，用户的"满意度"就很难。
- 不追求完美
  > 我们可以随着时间流逝了解系统行为之后优化 SLO 的定义。刚开始可以以一个松散的目标开始，逐渐收紧。这比一开始制定一个困难的目标，在出现问题时放松要好的多。

#### 控制手段

SLI 和 SLO 在决策系统运维时也非常有用

1. 监控并且度量系统的 SLI
2. 比较 SLI 和 SLO，以决定是否需要执行操作
3. 如果需要执行操作，则要决定究竟什么操作需要被执行，以便满足目标
4. 执行这些操作
   例如，如果在第 2 步中，请求延迟正在上涨，无操作的话，会在几个小时内超出 SLO 范围。第 3 步则会测试服务器是否是 CPU 资源不够，同时增加一些 CPU 来分散负载。没有 SLO 的话，我们就不知道是否(或者何时)需要执行该操作。

## 减少琐事

> 如果系统正常运转中需要人工干预，应该将此视为一种 BUG。"正常"的定义会随着系统的进步而不断改变。

SRE 要把更多的时间花费在长期项目研发上而非日常运维中。因为术语`日常运维`可能会被误解，我们在这里使用一个专门的词语 - `琐事(toil)`。

### 琐事的定义

- 手动性
- 重复性的
- 可以被自动化的
- 战术性的
- 没有持久价值
- 与服务同步线性增长

### 什么算做工程工作

典型的 SRE 活动分为如下几类

- 软件工程
- 系统工程
- 琐事
- 流程负担

### 琐事繁多是不是一定不好

琐事不太多的时候，已知的和重复性的工作有一种让人平静的功效。琐事可能是低风险低压力的活动，有些员工甚至喜欢做这种类型的工作。
如果琐事特别繁重，那就应该非常担忧。
琐事有害的因素

- 职业停滞
- 士气低落
  另外，牺牲工程实践而做琐事会对 SRE 组织的整体发展造成损害
- 造成误解
- 进展缓慢
- 开创先例
- 促进摩擦产生
- 违反承诺

### 本章小结

如果我们都致力于每一周通过工程工作消除一点琐事，就可以持续性地整顿服务。我们就可以将更多的力量投入到扩大服务规模的工程工作上去，或者是进行下一代的服务的架构设计，又或者是建立一套跨 SRE 使用的工具链。让我们多创新，少干琐事吧！
